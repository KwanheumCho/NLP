{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Term _Project : Sentiment Analysis_RNN","provenance":[{"file_id":"1o0c24oNfWvVHvBkUugQVSEssHeV4Uo5Y","timestamp":1591865437694}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oE7je_5DpRi1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593352569984,"user_tz":-540,"elapsed":189705,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"9a60502f-6cbc-4280-a544-b41bc2946a13"},"source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","%cd Mecab-ko-for-Google-Colab\n","!bash install_mecab-ko_on_colab190912.sh"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 60, done.\u001b[K\n","remote: Counting objects: 100% (60/60), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 60 (delta 23), reused 20 (delta 5), pack-reused 0\u001b[K\n","Unpacking objects: 100% (60/60), done.\n","/content/Mecab-ko-for-Google-Colab\n","Installing konlpy.....\n","Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9b/e115101a833605b3c0e6f3a2bc1f285c95aaa1d93ab808314ca1bde63eed/JPype1-0.7.5-cp36-cp36m-manylinux2010_x86_64.whl (3.6MB)\n","\u001b[K     |████████████████████████████████| 3.6MB 41.5MB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.9MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Installing collected packages: colorama, JPype1, tweepy, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-0.7.5 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2020-06-28 13:53:14--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n","Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=u4AbFncK9%2B9vUMQO7yn%2FzTCYYjo%3D&Expires=1593354195&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n","--2020-06-28 13:53:15--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=u4AbFncK9%2B9vUMQO7yn%2FzTCYYjo%3D&Expires=1593354195&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.132.3\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.132.3|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.47MB/s    in 0.4s    \n","\n","2020-06-28 13:53:15 (3.47 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2020-06-28 13:54:50--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.2, 18.205.93.1, ...\n","Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=kdnw7iu8DY8S8kgbnvYMoyd%2BiXo%3D&Expires=1593354001&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n","--2020-06-28 13:54:50--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=kdnw7iu8DY8S8kgbnvYMoyd%2BiXo%3D&Expires=1593354001&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.250.188\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.250.188|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  33.3MB/s    in 1.4s    \n","\n","2020-06-28 13:54:52 (33.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","apt-get update\n","apt-get upgrade\n","apt install curl\n","apt install git\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","Done\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j5rCYWqzpV8T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593352570479,"user_tz":-540,"elapsed":184175,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchtext import data\n","import urllib.request\n","import pandas as pd\n","from konlpy.tag import Mecab\n","from torchtext.data import TabularDataset\n","from torchtext.data import Iterator"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tUvf-CwuIWa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593354320885,"user_tz":-540,"elapsed":777,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["BATCH_SIZE = 64\n","lr = 0.001\n","EPOCHS = 20\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SHwOAXLpYRH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593352572629,"user_tz":-540,"elapsed":1274,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"b3e5557b-1fd4-42b1-cd1d-a68aa045879c"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ratings_test.txt', <http.client.HTTPMessage at 0x7f9215b21048>)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"qnPcFM8SpjAX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593354322824,"user_tz":-540,"elapsed":834,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["\n","tokenizer = Mecab() #토크나이져로 Mecab 활용\n","\n","# Text 형태의 영화 리뷰들과 그에 해당하는 Label을 텐서로 바꿔줄 때 필요한 설정.\n","# torch text를 사용해서 이러한 설정정보를 담고 있는 ID, TEXT, LABEL 객체 설정 (총3개의 필드를 정의한다) \n","ID = data.Field(sequential = False,\n","                use_vocab = False) #ID는 실제로 사용되지 않는다.\n","\n","TEXT = data.Field(sequential=True,\n","                  use_vocab=True,\n","                  tokenize=tokenizer.morphs,\n","                  lower=True,\n","                  batch_first=True,\n","                  fix_length=20)\n","                  #include_lengths= True) #for packed pad\n","\n","LABEL = data.Field(sequential=False,\n","                   use_vocab=False,\n","                   is_target=True)\n","\n","\n"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOpWGuqBqudr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593354351471,"user_tz":-540,"elapsed":26351,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"9e1a5231-44a9-48b1-e164-09f89b0cb66e"},"source":["# Make Dataset + Tokenizing\n","train_data, test_data = TabularDataset.splits(\n","        path='.', train='ratings_train.txt', test='ratings_test.txt', format='tsv',\n","        fields=[('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)\n","\n","#print('train : {}'.format(len(train_data)))\n","#print('test : {}'.format(len(test_data)))\n","print(len(train_data))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["150000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZxT5MiGmq0au","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593353479732,"user_tz":-540,"elapsed":2857,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["# Make Vocab.\n","TEXT.build_vocab(train_data, min_freq=10, vectors=\"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tsdJ5dRwCM2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593354352998,"user_tz":-540,"elapsed":25318,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["# use above glove or here just word2vec\n","# Make Vocab.\n","TEXT.build_vocab(train_data, min_freq=5)\n","LABEL.build_vocab(train_data)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJaa6rBjuPuH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593354354424,"user_tz":-540,"elapsed":1411,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"1003b0ac-ecf1-42d6-ee27-f13a3ce1a0f6"},"source":["# Make validation data (80% training data, 20% validation data)\n","train_data, val_data = train_data.split(split_ratio=0.8)\n","#train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))\n","\n","\n","# Make Iterator (for Batch)\n","#train_iter = Iterator(dataset=train_data, batch_size = BATCH_SIZE, sort_within_batch = True, sort_key = lambda x: len(x.text), shuffle=True)\n","#test_iter = Iterator(dataset=test_data, batch_size = BATCH_SIZE, sort_within_batch = True, sort_key = lambda x: len(x.text),shuffle=False)\n","#val_iter = Iterator(dataset=val_data, batch_size = BATCH_SIZE, sort_within_batch = True, sort_key = lambda x: len(x.text), shuffle=False)\n","train_iter, val_iter, test_iter = data.BucketIterator.splits(\n","    (train_data, val_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    sort_key = lambda x : len(x.text),\n","    device=DEVICE)\n","#train_iter = Iterator(dataset=train_data, batch_size = BATCH_SIZE)\n","#test_iter = Iterator(dataset=test_data, batch_size = BATCH_SIZE)\n","#val_iter = Iterator(dataset=val_data, batch_size = BATCH_SIZE)\n","\n","# Define number of words and number of lables in the 'word vocabuary'\n","vocab_size = len(TEXT.vocab)\n","n_classes = 2\n","\n","print(\"[train]: %d [val]: %d [test]: %d [words]: %d [class] %d\"\n","      % (len(train_data),len(val_data), len(test_data), vocab_size, n_classes))\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[train]: 120000 [val]: 30000 [test]: 50000 [words]: 16037 [class] 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jcs9mk9wvClZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"ok","timestamp":1593320678825,"user_tz":-540,"elapsed":1073,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"d282fd91-910c-402c-cb86-8746ef99ca28"},"source":["a,b = next(iter(train_iter)).text\n","print(a)\n","print(b)\n","print(len(torch.nonzero(b)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[ 934,    5,   23,  ..., 2668,  132,    9],\n","        [4112,   10, 7875,  ...,    0,  886, 4243],\n","        [2381, 3612,   62,  ...,   79,  543,  170],\n","        ...,\n","        [2360,  822,  332,  ...,    8,    4,   18],\n","        [5518, 7153,    3,  ..., 2270,  182,   11],\n","        [5045,    3,  146,  ..., 1615,   14,  715]], device='cuda:0')\n","tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n","        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n","        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n","        20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')\n","64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OFVTsvYauQam","colab_type":"code","colab":{}},"source":["'''\n","# model = RNN(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n","\n","class RNN(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n","        super(RNN, self).__init__()\n","        self.n_layers = n_layers # number of layer\n","        self.hidden_dim = hidden_dim # hidden layer의 차원값\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n","        self.embed = nn.Embedding(n_vocab, embed_dim) # n_vocab = number of words in the vocab. / embeded_dim = 임베딩된 단어 텐서가 가지는 차원(임베딩할 벡터의 차원)\n","        self.out = nn.Linear(self.hidden_dim, n_classes) # 압축된 텐서를 신경망에 통과시켜 클래스에 대한 예측 출력\n","\n","    def forward(self, x):\n","        # |x| = (batch_size, max_length) = ( 64, 20)\n","        \n","        embedded_x = self.embed(x)\n","        # |embedded_x| = (batch_size, max_length, embed_dim)\n","        h_0 = self._init_state(batch_size=x.size(0)) # Define 1st hidden layer\n","        # |h_0| , |hidden| = (1, batch_size, hid_dim) = (1, 64, 256)\n","        output, hidden = self.rnn(embedded_x)  # [i, b, h]\n","        # |output| = (batch_size, max_length, hidden_dim) = (64, 20, 256)\n","        # output is the concatenation of the hidden state from every step, hidden is the final hidden state\n","        # output[:, -1, :] == hidden.squeeze(0) = (64, 256)\n","        out = self.dropout(hidden.squeeze(0))\n","        logit = self.out(out)  # [b, h] -> [b, out_dim] (64, 2)\n","        #print(logit.size())\n","        return logit\n","    \n","    def _init_state(self, batch_size=1):\n","        weight = next(self.parameters()).data\n","        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","  '''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XNNlTgwQrNx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593354354425,"user_tz":-540,"elapsed":1399,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["\n","# For LSTM\n","# model = RNN(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n","\n","class RNN(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2, bidirectional = False):\n","        super(RNN, self).__init__()\n","        self.n_layers = n_layers # number of layer\n","        self.hidden_dim = hidden_dim # hidden layer의 차원값\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.rnn = nn.LSTM(embed_dim, self.hidden_dim, num_layers=self.n_layers, bidirectional = bidirectional,batch_first=True)\n","        self.embed = nn.Embedding(n_vocab, embed_dim) # n_vocab = number of words in the vocab. / embeded_dim = 임베딩된 단어 텐서가 가지는 차원(임베딩할 벡터의 차원)\n","        self.out = nn.Linear(self.hidden_dim*2, n_classes) # 압축된 텐서를 신경망에 통과시켜 클래스에 대한 예측 출력\n","\n","    def forward(self, x):\n","        # |x| = (batch_size, max_length) = ( 64, 20)\n","        \n","        embedded_x = self.embed(x)\n","        # |embedded_x| = (batch_size, max_length, embed_dim)\n","        h_0 = self._init_state(batch_size=x.size(0)) # Define 1st hidden layer\n","        # |h_0| , |hidden| = (1, batch_size, hid_dim) = (1, 64, 256)\n","        output, (hidden, cell) = self.rnn(embedded_x)  # [i, b, h]\n","        # |output| = (batch_size, max_length, hidden_dim) = (64, 20, 256)\n","        # output is the concatenation of the hidden state from every step, hidden is the final hidden state\n","        # output[:, -1, :] == hidden.squeeze(0) = (64, 256)\n","        #out = self.dropout(hidden.squeeze(0))\n","        out = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        logit = self.out(out)  # [b, h] -> [b, out_dim] (64, 2)\n","        #print(logit.size())\n","        return logit\n","    \n","    def _init_state(self, batch_size=1):\n","        weight = next(self.parameters()).data\n","        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","  "],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"M26KKRrEz_fG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593353117194,"user_tz":-540,"elapsed":1808,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["'''\n","# For LSTM packed padded sequence\n","# model = RNN(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n","\n","class RNN(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes,  pad_idx, dropout_p=0.2, bidirectional = False):\n","        super(RNN, self).__init__()\n","        self.n_layers = n_layers # number of layer\n","        self.hidden_dim = hidden_dim # hidden layer의 차원값\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.rnn = nn.LSTM(embed_dim, self.hidden_dim, num_layers=self.n_layers, bidirectional = bidirectional)\n","        self.embed = nn.Embedding(n_vocab, embed_dim, padding_idx= pad_idx) # n_vocab = number of words in the vocab. / embeded_dim = 임베딩된 단어 텐서가 가지는 차원(임베딩할 벡터의 차원)\n","        self.out = nn.Linear(self.hidden_dim*2, n_classes) # 압축된 텐서를 신경망에 통과시켜 클래스에 대한 예측 출력\n","\n","    def forward(self, x, text_lengths):\n","        # |x| = (batch_size, max_length) = ( 64, 20)\n","        \n","        embedded_x = self.embed(x)\n","        embedded_x = embedded_x.view( embedded_x.size(1), embedded_x.size(0), -1)\n","        #print(embedded_x.size())\n","        #print(text_lengths)\n","        #print(text_lengths.size())\n","        # |embedded_x| = (batch_size, max_length, embed_dim)\n","        #print(x)\n","        #print(text_lengths)\n","        packed_emb = nn.utils.rnn.pack_padded_sequence(embedded_x, text_lengths)\n","        packed_out, (hidden, cell) = self.rnn(packed_emb)\n","        output, output_len = nn.utils.rnn.pad_packed_sequence(packed_out)\n","\n","        \n","        # |output| = (batch_size, max_length, hidden_dim*num directions) = (64, 20, 256*?)\n","        # output is the concatenation of the hidden state from every step, hidden is the final hidden state\n","        # output[:, -1, :] == hidden.squeeze(0) = (64, 256)\n","        #out = self.dropout(hidden.squeeze(0))\n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        #print(hidden.size())\n","        logit = self.out(hidden)  # [b, h] -> [b, out_dim] (64, 2)\n","        return logit\n","    \n","    def _init_state(self, batch_size=1):\n","        weight = next(self.parameters()).data\n","        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","  '''"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnz6TT4YwD1c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593354366646,"user_tz":-540,"elapsed":885,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["## packed pad train\n","'''\n","def train(model, optimizer, train_iter):\n","    model.train()\n","    for b, batch in enumerate(train_iter):\n","        #x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n","        optimizer.zero_grad()\n","        text, text_lengths = batch.text\n","        text = text.to(DEVICE)\n","        label = batch.label.to(DEVICE)\n","        if(len(torch.nonzero(text_lengths))==64) : ##there are exception that length = 0 ;\n","          logit = model(text, text_lengths).squeeze(1)\n","          loss = F.cross_entropy(logit, label)\n","          loss.backward()\n","          optimizer.step()\n","'''\n","## basic train\n","def train(model, optimizer, train_iter):\n","    model.train()\n","    for b, batch in enumerate(train_iter):\n","        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n","        optimizer.zero_grad()\n","\n","        logit = model(x)\n","        loss = F.cross_entropy(logit, y)\n","        loss.backward()\n","        optimizer.step()"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOGvcnHPwE_X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593355166741,"user_tz":-540,"elapsed":791,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}}},"source":["##packed padded eval\n","'''\n","def evaluate(model, val_iter):\n","    model.eval()\n","    corrects, total_loss = 0, 0\n","    for batch in val_iter:\n","      text, text_lengths = batch.text\n","      text = text.to(DEVICE)\n","      label = batch.label.to(DEVICE)\n","      if(len(torch.nonzero(text_lengths))==64) : ##there are exception that length = 0 ;\n","        logit = model(text, text_lengths).squeeze(1)\n","        loss = F.cross_entropy(logit, label, reduction = 'sum')\n","        total_loss += loss.item()\n","        corrects += (logit.max(1)[1].view(label.size()).data == label.data).sum()\n","    size = len(val_iter.dataset)\n","    avg_loss = total_loss / size\n","    avg_accuracy = 100.0 * corrects / size\n","    return avg_loss, avg_accuracy\n","#pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n","#print(pad_idx)\n","'''\n","## basic code\n","def evaluate(model, val_iter):\n","    model.eval()\n","    corrects, total_loss = 0, 0\n","    for batch in val_iter:\n","        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n","        logit = model(x)\n","        loss = F.cross_entropy(logit, y, reduction='sum')\n","        total_loss += loss.item()\n","        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n","    size = len(val_iter.dataset)\n","    avg_loss = total_loss / size\n","    avg_accuracy = 100.0 * corrects / size\n","    return avg_loss, avg_accuracy\n","model = RNN(1, 256, vocab_size, 128, n_classes, 0.2, True).to(DEVICE)\n","#model = RNN(2, 256, vocab_size, 200, 2,  pad_idx, 0.2, False)\n","#model = GRU(1, 256, vocab_size, 200, n_classes, 0.2).to(DEVICE)\n","#n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9KdZULowGFH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1593355784852,"user_tz":-540,"elapsed":614016,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"ec4d790e-e46c-45a1-8565-a9807e99482e"},"source":["best_val_loss = None\n","model = model.to(DEVICE)\n","\n","for e in range(1, EPOCHS+1):\n","    train(model, optimizer, train_iter)\n","    val_loss, val_accuracy = evaluate(model, val_iter)\n","\n","    print(\"[epoch: %d] val loss:%5.2f | val accu:%5.2f\" % (e, val_loss, val_accuracy))\n","    \n","    # 검증 오차가 가장 적은 최적의 모델을 저장\n","    if not best_val_loss or val_loss < best_val_loss:\n","        if not os.path.isdir(\"snapshot\"):\n","            os.makedirs(\"snapshot\")\n","        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n","        best_val_loss = val_loss"],"execution_count":47,"outputs":[{"output_type":"stream","text":["[epoch: 1] val loss: 0.37 | val accu:83.53\n","[epoch: 2] val loss: 0.35 | val accu:84.59\n","[epoch: 3] val loss: 0.36 | val accu:85.27\n","[epoch: 4] val loss: 0.41 | val accu:84.90\n","[epoch: 5] val loss: 0.52 | val accu:84.73\n","[epoch: 6] val loss: 0.62 | val accu:84.46\n","[epoch: 7] val loss: 0.69 | val accu:84.26\n","[epoch: 8] val loss: 0.79 | val accu:84.25\n","[epoch: 9] val loss: 0.79 | val accu:84.00\n","[epoch: 10] val loss: 0.86 | val accu:84.06\n","[epoch: 11] val loss: 0.85 | val accu:84.03\n","[epoch: 12] val loss: 0.92 | val accu:84.06\n","[epoch: 13] val loss: 0.98 | val accu:84.18\n","[epoch: 14] val loss: 0.93 | val accu:84.20\n","[epoch: 15] val loss: 0.94 | val accu:84.24\n","[epoch: 16] val loss: 0.97 | val accu:84.26\n","[epoch: 17] val loss: 0.99 | val accu:84.48\n","[epoch: 18] val loss: 0.99 | val accu:84.18\n","[epoch: 19] val loss: 1.02 | val accu:84.28\n","[epoch: 20] val loss: 1.01 | val accu:83.81\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h61O9dvUwHYe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593355792986,"user_tz":-540,"elapsed":4448,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"75faceb8-ae4c-4302-ae5a-c87614462eb3"},"source":["model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n","test_loss, test_acc = evaluate(model, test_iter)\n","print('test loss: %5.2f | test accu: %5.2f' % (test_loss, test_acc))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["test loss:  0.35 | test accu: 84.53\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mu0kVcqUH8W3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"error","timestamp":1593279508569,"user_tz":-540,"elapsed":18643,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"7692b0da-5033-4293-fd93-1a4064033a7f"},"source":["best_val_loss = None\n","for e in range(1, EPOCHS+1):\n","    train(model, optimizer, train_iter)\n","    val_loss, val_accuracy = evaluate(model, val_iter)\n","\n","    print(\"[epoch: %d] val loss:%5.2f | val accu:%5.2f\" % (e, val_loss, val_accuracy))\n","    \n","    # 검증 오차가 가장 적은 최적의 모델을 저장\n","    if not best_val_loss or val_loss < best_val_loss:\n","        if not os.path.isdir(\"snapshot\"):\n","            os.makedirs(\"snapshot\")\n","        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n","        best_val_loss = val_loss"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-177-febf9455e216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-163-0ed1666793b5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_iter)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Ye8o3zWTJBDp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593267467191,"user_tz":-540,"elapsed":3430,"user":{"displayName":"‍조관흠(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"14678811557423603896"}},"outputId":"7ea05ffc-d7cd-4278-a372-ae787f016387"},"source":["model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n","test_loss, test_acc = evaluate(model, test_iter)\n","print('test loss: %5.2f | test accu: %5.2f' % (test_loss, test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test loss:  0.49 | test accu: 78.17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gVzUp5VbvLH_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNGtjmfvvLKy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zdxpVdEvLQj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRwPpirksJuU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6Oq_iGosJyW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEA1Xn0fsJ2I","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}